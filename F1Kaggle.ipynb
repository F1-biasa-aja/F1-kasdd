{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **KASDD F1 Lap time - Biasa Aja**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sumber**\n",
    "> https://www.datacamp.com/tutorial/random-forests-classifier-python <br>\n",
    "> https://www.freecodecamp.org/news/how-to-use-the-tree-based-algorithm-for-machine-learning/ <br>\n",
    "> https://forecastegy.com/posts/does-random-forest-need-feature-scaling-or-normalization/#:~:text=If%20you%20are%20using%20Random,does%20not%20require%20feature%20scaling. <br>\n",
    "> https://medium.com/@jackiee.jecksom/clustering-and-principal-component-analysis-pca-from-sklearn-c8ea5fed6648 <br>\n",
    "> https://365datascience.com/tutorials/python-tutorials/pca-k-means/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library dan data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.stats as scp\n",
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "from sklearn.preprocessing import LabelEncoder, Normalizer, StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import chi2, mutual_info_regression, mutual_info_classif, SelectKBest, mutual_info_regression, SelectPercentile, mutual_info_regression, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, CategoricalNB\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold\n",
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import SilhouetteVisualizer, KElbowVisualizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "train = pd.read_csv(\"f1_train.csv\")\n",
    "train = train.drop(axis=1, columns=[\"ID\"])\n",
    "\n",
    "f1_classif = pd.read_csv(\"f1_test_classif.csv\")\n",
    "id_classif = f1_classif['ID']\n",
    "f1_classif = f1_classif.drop(axis=1, columns=[\"ID\"])\n",
    "\n",
    "f1_reg = pd.read_csv(\"f1_test_reg.csv\")\n",
    "id_reg = f1_reg['ID']\n",
    "f1_reg = f1_reg.drop(axis=1, columns=[\"ID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cek_duplicates(df):\n",
    "    if df.duplicated().sum() > 0:\n",
    "        print(\"Terdapat\", df.duplicated().sum(), \"pasang data yang redundan\")\n",
    "        display(df[df.duplicated()])\n",
    "    else:\n",
    "        print(\"Tidak ada data yang redundan\")\n",
    "\n",
    "def cek_null(df):\n",
    "    col_na = df.isnull().sum().sort_values(ascending=True)\n",
    "    percent = col_na*100 / len(df)\n",
    "\n",
    "    missing_data = pd.concat([col_na, percent], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "    if (missing_data[missing_data['Total'] > 0].shape[0] == 0):\n",
    "        print(\"Tidak ditemukan missing value pada dataset\")\n",
    "\n",
    "    else:\n",
    "        print(missing_data[missing_data['Total'] > 0])\n",
    "\n",
    "def cek_outlier(df):\n",
    "    df_numerical = df.select_dtypes(include=['float64', 'int64']) \n",
    "    Q1 = df_numerical.quantile(0.25, numeric_only=True)\n",
    "    Q3 = df_numerical.quantile(0.75, numeric_only=True)\n",
    "\n",
    "    # Menghitung RUB dan RLB.\n",
    "    IQR = Q3 - Q1\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Menampilkan banyaknya outlier pada atribut.\n",
    "    outliers = (df_numerical < lower_limit) | (df_numerical > upper_limit)\n",
    "\n",
    "    # Menghitung dan menampilkan persentase outlier pada tiap atribut.\n",
    "    percentage_outliers = (outliers.sum() / len(df)) * 100\n",
    "    print(\"Persentase Outlier pada tiap atribut:\")\n",
    "    print(percentage_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Total    Percent\n",
      "IsPersonalBest          5   0.212857\n",
      "Sector2SessionTime      5   0.212857\n",
      "Sector2Time             5   0.212857\n",
      "SpeedI2                 5   0.212857\n",
      "Sector3SessionTime     13   0.553427\n",
      "Sector3Time            13   0.553427\n",
      "LapTime                41   1.745424\n",
      "Sector1Time            52   2.213708\n",
      "Sector1SessionTime     58   2.469136\n",
      "SpeedFL                95   4.044274\n",
      "SpeedST               239  10.174542\n",
      "SpeedI1               359  15.283099\n",
      "PitOutTime           2230  94.934014\n",
      "PitInTime            2259  96.168582\n",
      "DeletedReason        2312  98.424862\n"
     ]
    }
   ],
   "source": [
    "cek_null(f1_classif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Total    Percent\n",
      "IsPersonalBest          3   0.127768\n",
      "Sector2SessionTime      3   0.127768\n",
      "Sector2Time             3   0.127768\n",
      "SpeedI2                 3   0.127768\n",
      "Sector3SessionTime      8   0.340716\n",
      "Sector3Time             8   0.340716\n",
      "LapTime                32   1.362862\n",
      "Sector1Time            62   2.640545\n",
      "Sector1SessionTime     65   2.768313\n",
      "SpeedFL                91   3.875639\n",
      "SpeedST               225   9.582624\n",
      "SpeedI1               364  15.502555\n",
      "PitOutTime           2215  94.335605\n",
      "PitInTime            2261  96.294719\n",
      "DeletedReason        2314  98.551959\n"
     ]
    }
   ],
   "source": [
    "cek_null(f1_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Total    Percent\n",
      "IsPersonalBest         30   0.159676\n",
      "SpeedI2                39   0.207579\n",
      "Sector2SessionTime     39   0.207579\n",
      "Sector2Time            39   0.207579\n",
      "Sector3SessionTime     92   0.489674\n",
      "Sector3Time            92   0.489674\n",
      "LapTime               290   1.543538\n",
      "Sector1Time           407   2.166276\n",
      "Sector1SessionTime    444   2.363211\n",
      "SpeedFL               775   4.124973\n",
      "SpeedST              1692   9.005748\n",
      "SpeedI1              2917  15.525868\n",
      "PitOutTime          17749  94.469874\n",
      "PitInTime           18053  96.087928\n",
      "DeletedReason       18477  98.344688\n"
     ]
    }
   ],
   "source": [
    "cek_null(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_classif = f1_classif.drop(axis=1, columns=['PitOutTime', 'PitInTime', 'DeletedReason'])\n",
    "f1_reg = f1_reg.drop(axis=1, columns=['PitOutTime', 'PitInTime', 'DeletedReason'])\n",
    "train = train.drop(axis=1, columns=['PitOutTime', 'PitInTime', 'DeletedReason'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data_type_and_distribution(df):\n",
    "    print(\"Menampilkan informasi dataset dan tipe data\")\n",
    "    print('#'*50)\n",
    "    df.info()\n",
    "    print('#'*50)\n",
    "    print(\"Menampilkan distribusi data numerik\")\n",
    "    numerics = ['SpeedI2', 'SpeedFL', 'SpeedST', 'SpeedI1']\n",
    "    for col in numerics:\n",
    "        df_feature = f1_classif[col]\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.title(f'Distribusi data {col}')\n",
    "        sns.kdeplot(df_feature, fill=True)\n",
    "        plt.show()\n",
    "    print(\"Menampilkan Modus dari data kategorikal\")\n",
    "    categoricals = [\"IsPersonalBest\", \"Sector2SessionTime\", \"Sector2Time\",\"Sector3SessionTime\", \"Sector3Time\", \"LapTime\", \"Sector1Time\", \"Sector1SessionTime\"]\n",
    "    for col in categoricals:\n",
    "        print(f\"Mode for {col} = {f1_classif[col].mode()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_null_mean(df):\n",
    "    mean = df.mean()\n",
    "    filled_df = df.fillna(mean)\n",
    "    return filled_df\n",
    "def fill_null_median(df):\n",
    "    median = df.median()\n",
    "    filled_df = df.fillna(median)\n",
    "    return filled_df\n",
    "def fill_null_mode(df):\n",
    "    mode = df.mode()[0]\n",
    "    filled_df = df.fillna(mode)\n",
    "    return filled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_reg['SpeedI2'] = fill_null_median(f1_reg['SpeedI2'])\n",
    "f1_reg['SpeedFL'] = fill_null_median(f1_reg['SpeedFL'])\n",
    "f1_reg['SpeedST'] = fill_null_mean(f1_reg['SpeedST'])\n",
    "f1_reg['SpeedI1'] = fill_null_median(f1_reg['SpeedI1'])\n",
    "f1_reg['IsPersonalBest'] = fill_null_mode(f1_reg['IsPersonalBest'])\n",
    "f1_reg['Sector2SessionTime'] = fill_null_mode(f1_reg['Sector2SessionTime'])\n",
    "f1_reg['Sector2Time'] = fill_null_mode(f1_reg['Sector2Time'])\n",
    "f1_reg['Sector3SessionTime'] = fill_null_mode(f1_reg['Sector3SessionTime'])\n",
    "f1_reg['Sector3Time'] = fill_null_mode(f1_reg['Sector3Time'])\n",
    "f1_reg['LapTime'] = fill_null_mode(f1_reg['LapTime'])\n",
    "f1_reg['Sector1Time'] = fill_null_mode(f1_reg['Sector1Time'])\n",
    "f1_reg['Sector1SessionTime'] = fill_null_mode(f1_reg['Sector1SessionTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_classif['SpeedI2'] = fill_null_median(f1_classif['SpeedI2'])\n",
    "f1_classif['SpeedFL'] = fill_null_median(f1_classif['SpeedFL'])\n",
    "f1_classif['SpeedST'] = fill_null_mean(f1_classif['SpeedST'])\n",
    "f1_classif['SpeedI1'] = fill_null_median(f1_classif['SpeedI1'])\n",
    "f1_classif['IsPersonalBest'] = fill_null_mode(f1_classif['IsPersonalBest'])\n",
    "f1_classif['Sector2SessionTime'] = fill_null_mode(f1_classif['Sector2SessionTime'])\n",
    "f1_classif['Sector2Time'] = fill_null_mode(f1_classif['Sector2Time'])\n",
    "f1_classif['Sector3SessionTime'] = fill_null_mode(f1_classif['Sector3SessionTime'])\n",
    "f1_classif['Sector3Time'] = fill_null_mode(f1_classif['Sector3Time'])\n",
    "f1_classif['LapTime'] = fill_null_mode(f1_classif['LapTime'])\n",
    "f1_classif['Sector1Time'] = fill_null_mode(f1_classif['Sector1Time'])\n",
    "f1_classif['Sector1SessionTime'] = fill_null_mode(f1_classif['Sector1SessionTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['SpeedI2'] = fill_null_median(train['SpeedI2'])\n",
    "train['SpeedFL'] = fill_null_median(train['SpeedFL'])\n",
    "train['SpeedST'] = fill_null_mean(train['SpeedST'])\n",
    "train['SpeedI1'] = fill_null_median(train['SpeedI1'])\n",
    "train['IsPersonalBest'] = fill_null_mode(train['IsPersonalBest'])\n",
    "train['Sector2SessionTime'] = fill_null_mode(train['Sector2SessionTime'])\n",
    "train['Sector2Time'] = fill_null_mode(train['Sector2Time'])\n",
    "train['Sector3SessionTime'] = fill_null_mode(train['Sector3SessionTime'])\n",
    "train['Sector3Time'] = fill_null_mode(train['Sector3Time'])\n",
    "train['LapTime'] = fill_null_mode(train['LapTime'])\n",
    "train['Sector1Time'] = fill_null_mode(train['Sector1Time'])\n",
    "train['Sector1SessionTime'] = fill_null_mode(train['Sector1SessionTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>LapTime</th>\n",
       "      <th>Stint</th>\n",
       "      <th>Sector1Time</th>\n",
       "      <th>Sector2Time</th>\n",
       "      <th>Sector3Time</th>\n",
       "      <th>Sector1SessionTime</th>\n",
       "      <th>Sector2SessionTime</th>\n",
       "      <th>Sector3SessionTime</th>\n",
       "      <th>SpeedI1</th>\n",
       "      <th>...</th>\n",
       "      <th>LapStartTime</th>\n",
       "      <th>Deleted</th>\n",
       "      <th>AirTemp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>TrackTemp</th>\n",
       "      <th>WindDirection</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>Pos_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 days 02:26:25.496000</td>\n",
       "      <td>0 days 00:01:40.943000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0 days 00:00:46.163000</td>\n",
       "      <td>0 days 00:00:28.979000</td>\n",
       "      <td>0 days 00:00:25.801000</td>\n",
       "      <td>0 days 02:25:36.926000</td>\n",
       "      <td>0 days 02:26:05.905000</td>\n",
       "      <td>0 days 02:26:31.706000</td>\n",
       "      <td>283.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 02:24:44.553000</td>\n",
       "      <td>False</td>\n",
       "      <td>17.1</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>False</td>\n",
       "      <td>24.8</td>\n",
       "      <td>157</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Participant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 days 01:13:51.732000</td>\n",
       "      <td>0 days 00:01:48.067000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0 days 00:00:39.129000</td>\n",
       "      <td>0 days 00:00:43.601000</td>\n",
       "      <td>0 days 00:00:25.337000</td>\n",
       "      <td>0 days 01:12:42.794000</td>\n",
       "      <td>0 days 01:13:26.395000</td>\n",
       "      <td>0 days 01:13:51.732000</td>\n",
       "      <td>199.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 01:12:03.665000</td>\n",
       "      <td>False</td>\n",
       "      <td>25.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1008.5</td>\n",
       "      <td>False</td>\n",
       "      <td>43.3</td>\n",
       "      <td>275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Podium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 days 02:22:35.139000</td>\n",
       "      <td>0 days 00:01:22.881000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0 days 00:00:28.890000</td>\n",
       "      <td>0 days 00:00:18.554000</td>\n",
       "      <td>0 days 00:00:35.437000</td>\n",
       "      <td>0 days 02:21:41.150000</td>\n",
       "      <td>0 days 02:21:59.704000</td>\n",
       "      <td>0 days 02:22:35.141000</td>\n",
       "      <td>275.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 02:21:12.258000</td>\n",
       "      <td>False</td>\n",
       "      <td>17.6</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1018.2</td>\n",
       "      <td>False</td>\n",
       "      <td>29.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Participant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0 days 01:03:36.822000</td>\n",
       "      <td>0 days 00:01:31.585000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0 days 00:00:28.315000</td>\n",
       "      <td>0 days 00:00:28.929000</td>\n",
       "      <td>0 days 00:00:30.478000</td>\n",
       "      <td>0 days 01:04:58.279000</td>\n",
       "      <td>0 days 01:03:06.412000</td>\n",
       "      <td>0 days 01:03:36.927000</td>\n",
       "      <td>266.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 01:02:04.960000</td>\n",
       "      <td>False</td>\n",
       "      <td>17.6</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>False</td>\n",
       "      <td>29.5</td>\n",
       "      <td>135</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Podium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 days 01:45:40.072000</td>\n",
       "      <td>0 days 00:01:34.742000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0 days 00:00:34.895000</td>\n",
       "      <td>0 days 00:00:29.874000</td>\n",
       "      <td>0 days 00:00:29.973000</td>\n",
       "      <td>0 days 01:44:40.174000</td>\n",
       "      <td>0 days 01:45:10.048000</td>\n",
       "      <td>0 days 01:45:40.021000</td>\n",
       "      <td>274.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 01:44:05.330000</td>\n",
       "      <td>False</td>\n",
       "      <td>26.1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>False</td>\n",
       "      <td>31.0</td>\n",
       "      <td>271</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18783</th>\n",
       "      <td>0 days 01:27:00.913000</td>\n",
       "      <td>0 days 00:01:25.235000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0 days 00:00:30.620000</td>\n",
       "      <td>0 days 00:00:30.668000</td>\n",
       "      <td>0 days 00:00:23.947000</td>\n",
       "      <td>0 days 01:26:06.294000</td>\n",
       "      <td>0 days 01:26:36.962000</td>\n",
       "      <td>0 days 01:27:00.909000</td>\n",
       "      <td>276.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 01:25:35.678000</td>\n",
       "      <td>False</td>\n",
       "      <td>29.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>988.4</td>\n",
       "      <td>False</td>\n",
       "      <td>49.9</td>\n",
       "      <td>252</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Participant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18784</th>\n",
       "      <td>0 days 01:21:32.309000</td>\n",
       "      <td>0 days 00:01:40.363000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0 days 00:00:29.488000</td>\n",
       "      <td>0 days 00:00:42.838000</td>\n",
       "      <td>0 days 00:00:28.037000</td>\n",
       "      <td>0 days 01:20:21.469000</td>\n",
       "      <td>0 days 01:21:04.307000</td>\n",
       "      <td>0 days 01:21:32.344000</td>\n",
       "      <td>297.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 01:19:51.946000</td>\n",
       "      <td>False</td>\n",
       "      <td>30.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>False</td>\n",
       "      <td>36.8</td>\n",
       "      <td>145</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Participant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18785</th>\n",
       "      <td>0 days 02:00:31.678000</td>\n",
       "      <td>0 days 00:01:52.495000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0 days 00:00:32.659000</td>\n",
       "      <td>0 days 00:00:49.567000</td>\n",
       "      <td>0 days 00:00:30.269000</td>\n",
       "      <td>0 days 01:59:11.871000</td>\n",
       "      <td>0 days 02:00:01.438000</td>\n",
       "      <td>0 days 02:00:31.707000</td>\n",
       "      <td>309.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 01:58:39.183000</td>\n",
       "      <td>False</td>\n",
       "      <td>17.6</td>\n",
       "      <td>66.0</td>\n",
       "      <td>966.7</td>\n",
       "      <td>False</td>\n",
       "      <td>30.3</td>\n",
       "      <td>146</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Participant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18786</th>\n",
       "      <td>0 days 01:07:59.947000</td>\n",
       "      <td>0 days 00:01:25.938000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0 days 00:00:30.564000</td>\n",
       "      <td>0 days 00:00:31.370000</td>\n",
       "      <td>0 days 00:00:24.004000</td>\n",
       "      <td>0 days 01:07:04.556000</td>\n",
       "      <td>0 days 01:07:35.926000</td>\n",
       "      <td>0 days 01:07:59.930000</td>\n",
       "      <td>256.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 01:06:34.009000</td>\n",
       "      <td>False</td>\n",
       "      <td>28.8</td>\n",
       "      <td>33.0</td>\n",
       "      <td>988.5</td>\n",
       "      <td>False</td>\n",
       "      <td>50.1</td>\n",
       "      <td>134</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Participant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18787</th>\n",
       "      <td>0 days 02:04:03.127000</td>\n",
       "      <td>0 days 00:02:25.892000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0 days 00:00:52.231000</td>\n",
       "      <td>0 days 00:00:53.937000</td>\n",
       "      <td>0 days 00:00:39.724000</td>\n",
       "      <td>0 days 02:02:29.417000</td>\n",
       "      <td>0 days 02:03:23.354000</td>\n",
       "      <td>0 days 02:04:03.078000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 02:01:37.235000</td>\n",
       "      <td>False</td>\n",
       "      <td>20.9</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1001.2</td>\n",
       "      <td>False</td>\n",
       "      <td>29.7</td>\n",
       "      <td>246</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Point</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18787 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Time                 LapTime  Stint  \\\n",
       "0      0 days 02:26:25.496000  0 days 00:01:40.943000    6.0   \n",
       "1      0 days 01:13:51.732000  0 days 00:01:48.067000    1.0   \n",
       "2      0 days 02:22:35.139000  0 days 00:01:22.881000    2.0   \n",
       "3      0 days 01:03:36.822000  0 days 00:01:31.585000    1.0   \n",
       "4      0 days 01:45:40.072000  0 days 00:01:34.742000    2.0   \n",
       "...                       ...                     ...    ...   \n",
       "18783  0 days 01:27:00.913000  0 days 00:01:25.235000    2.0   \n",
       "18784  0 days 01:21:32.309000  0 days 00:01:40.363000    1.0   \n",
       "18785  0 days 02:00:31.678000  0 days 00:01:52.495000    3.0   \n",
       "18786  0 days 01:07:59.947000  0 days 00:01:25.938000    1.0   \n",
       "18787  0 days 02:04:03.127000  0 days 00:02:25.892000    3.0   \n",
       "\n",
       "                  Sector1Time             Sector2Time             Sector3Time  \\\n",
       "0      0 days 00:00:46.163000  0 days 00:00:28.979000  0 days 00:00:25.801000   \n",
       "1      0 days 00:00:39.129000  0 days 00:00:43.601000  0 days 00:00:25.337000   \n",
       "2      0 days 00:00:28.890000  0 days 00:00:18.554000  0 days 00:00:35.437000   \n",
       "3      0 days 00:00:28.315000  0 days 00:00:28.929000  0 days 00:00:30.478000   \n",
       "4      0 days 00:00:34.895000  0 days 00:00:29.874000  0 days 00:00:29.973000   \n",
       "...                       ...                     ...                     ...   \n",
       "18783  0 days 00:00:30.620000  0 days 00:00:30.668000  0 days 00:00:23.947000   \n",
       "18784  0 days 00:00:29.488000  0 days 00:00:42.838000  0 days 00:00:28.037000   \n",
       "18785  0 days 00:00:32.659000  0 days 00:00:49.567000  0 days 00:00:30.269000   \n",
       "18786  0 days 00:00:30.564000  0 days 00:00:31.370000  0 days 00:00:24.004000   \n",
       "18787  0 days 00:00:52.231000  0 days 00:00:53.937000  0 days 00:00:39.724000   \n",
       "\n",
       "           Sector1SessionTime      Sector2SessionTime      Sector3SessionTime  \\\n",
       "0      0 days 02:25:36.926000  0 days 02:26:05.905000  0 days 02:26:31.706000   \n",
       "1      0 days 01:12:42.794000  0 days 01:13:26.395000  0 days 01:13:51.732000   \n",
       "2      0 days 02:21:41.150000  0 days 02:21:59.704000  0 days 02:22:35.141000   \n",
       "3      0 days 01:04:58.279000  0 days 01:03:06.412000  0 days 01:03:36.927000   \n",
       "4      0 days 01:44:40.174000  0 days 01:45:10.048000  0 days 01:45:40.021000   \n",
       "...                       ...                     ...                     ...   \n",
       "18783  0 days 01:26:06.294000  0 days 01:26:36.962000  0 days 01:27:00.909000   \n",
       "18784  0 days 01:20:21.469000  0 days 01:21:04.307000  0 days 01:21:32.344000   \n",
       "18785  0 days 01:59:11.871000  0 days 02:00:01.438000  0 days 02:00:31.707000   \n",
       "18786  0 days 01:07:04.556000  0 days 01:07:35.926000  0 days 01:07:59.930000   \n",
       "18787  0 days 02:02:29.417000  0 days 02:03:23.354000  0 days 02:04:03.078000   \n",
       "\n",
       "       SpeedI1  ...            LapStartTime  Deleted  AirTemp  Humidity  \\\n",
       "0        283.0  ...  0 days 02:24:44.553000    False     17.1      68.0   \n",
       "1        199.0  ...  0 days 01:12:03.665000    False     25.0      49.0   \n",
       "2        275.0  ...  0 days 02:21:12.258000    False     17.6      57.0   \n",
       "3        266.0  ...  0 days 01:02:04.960000    False     17.6      67.0   \n",
       "4        274.0  ...  0 days 01:44:05.330000    False     26.1      55.0   \n",
       "...        ...  ...                     ...      ...      ...       ...   \n",
       "18783    276.0  ...  0 days 01:25:35.678000    False     29.3      32.0   \n",
       "18784    297.0  ...  0 days 01:19:51.946000    False     30.0      72.0   \n",
       "18785    309.0  ...  0 days 01:58:39.183000    False     17.6      66.0   \n",
       "18786    256.0  ...  0 days 01:06:34.009000    False     28.8      33.0   \n",
       "18787    153.0  ...  0 days 02:01:37.235000    False     20.9      63.0   \n",
       "\n",
       "      Pressure  Rainfall  TrackTemp WindDirection  WindSpeed      Pos_cat  \n",
       "0       1008.0     False       24.8           157        3.0  Participant  \n",
       "1       1008.5     False       43.3           275        1.0       Podium  \n",
       "2       1018.2     False       29.9             0        0.6  Participant  \n",
       "3       1007.7     False       29.5           135        1.8       Podium  \n",
       "4       1011.0     False       31.0           271        1.3        Point  \n",
       "...        ...       ...        ...           ...        ...          ...  \n",
       "18783    988.4     False       49.9           252        1.2  Participant  \n",
       "18784   1009.0     False       36.8           145        1.1  Participant  \n",
       "18785    966.7     False       30.3           146        1.1  Participant  \n",
       "18786    988.5     False       50.1           134        1.5  Participant  \n",
       "18787   1001.2     False       29.7           246        0.8        Point  \n",
       "\n",
       "[18787 rows x 27 columns]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_classif.drop_duplicates()\n",
    "f1_reg.drop_duplicates()\n",
    "train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persentase Outlier pada tiap atribut:\n",
      "Stint             0.255428\n",
      "SpeedI1           2.852278\n",
      "SpeedI2           0.510856\n",
      "SpeedFL           1.277139\n",
      "SpeedST           8.173691\n",
      "TyreLife          1.575138\n",
      "AirTemp           0.000000\n",
      "Humidity          0.000000\n",
      "Pressure         16.560238\n",
      "TrackTemp         0.000000\n",
      "WindDirection     0.000000\n",
      "WindSpeed         7.747978\n",
      "dtype: float64\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cek_outlier(f1_classif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persentase Outlier pada tiap atribut:\n",
      "Stint             0.340716\n",
      "SpeedI1           3.066440\n",
      "SpeedI2           0.255537\n",
      "SpeedFL           0.979557\n",
      "SpeedST           7.708688\n",
      "AirTemp           0.000000\n",
      "Humidity          0.000000\n",
      "Pressure         16.269165\n",
      "TrackTemp         0.000000\n",
      "WindDirection     0.000000\n",
      "WindSpeed         6.090290\n",
      "dtype: float64\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cek_outlier(f1_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persentase Outlier pada tiap atribut:\n",
      "Stint             0.298063\n",
      "SpeedI1           2.746434\n",
      "SpeedI2           0.548222\n",
      "SpeedFL           1.319991\n",
      "SpeedST           7.259953\n",
      "TyreLife          1.948052\n",
      "AirTemp           0.000000\n",
      "Humidity          0.000000\n",
      "Pressure         15.829253\n",
      "TrackTemp         0.000000\n",
      "WindDirection     0.000000\n",
      "WindSpeed         8.026400\n",
      "dtype: float64\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cek_outlier(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Atribut `Presure` digunakan untuk memprediksi `TyreLife`, sehingga tidak kami drop ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time : 2349 ['0 days 01:19:09.993000' '0 days 01:46:56.673000'\n",
      " '0 days 01:58:13.959000' ... '0 days 01:16:20.505000'\n",
      " '0 days 02:38:25.861000' '0 days 01:46:48.433000']\n",
      "\n",
      "\n",
      "LapTime : 2243 ['0 days 00:01:25.001000' '0 days 00:01:32.378000'\n",
      " '0 days 00:01:37.974000' ... '0 days 00:01:40.339000'\n",
      " '0 days 00:01:40.794000' '0 days 00:01:33.528000']\n",
      "\n",
      "\n",
      "Sector1Time : 2135 ['0 days 00:00:30.631000' '0 days 00:00:31.596000'\n",
      " '0 days 00:00:30.942000' ... '0 days 00:00:29.114000'\n",
      " '0 days 00:00:26.874000' '0 days 00:00:31.922000']\n",
      "\n",
      "\n",
      "Sector2Time : 2189 ['0 days 00:00:30.430000' '0 days 00:00:34.849000'\n",
      " '0 days 00:00:42.828000' ... '0 days 00:00:42.991000'\n",
      " '0 days 00:00:40.382000' '0 days 00:00:35.533000']\n",
      "\n",
      "\n",
      "Sector3Time : 2135 ['0 days 00:00:23.940000' '0 days 00:00:25.933000'\n",
      " '0 days 00:00:24.204000' ... '0 days 00:00:28.234000'\n",
      " '0 days 00:00:33.538000' '0 days 00:00:26.073000']\n",
      "\n",
      "\n",
      "Sector1SessionTime : 2290 ['0 days 01:18:15.630000' '0 days 01:45:55.886000'\n",
      " '0 days 01:57:06.877000' ... '0 days 01:15:09.320000'\n",
      " '0 days 02:37:11.926000' '0 days 01:45:46.824000']\n",
      "\n",
      "\n",
      "Sector2SessionTime : 2343 ['0 days 01:18:46.060000' '0 days 01:46:30.735000'\n",
      " '0 days 01:57:49.705000' ... '0 days 01:15:52.311000'\n",
      " '0 days 02:37:52.308000' '0 days 01:46:22.357000']\n",
      "\n",
      "\n",
      "Sector3SessionTime : 2336 ['0 days 01:19:10' '0 days 01:46:56.668000' '0 days 01:58:13.909000' ...\n",
      " '0 days 01:16:20.545000' '0 days 02:38:25.846000'\n",
      " '0 days 01:46:48.430000']\n",
      "\n",
      "\n",
      "Compound : 5 ['MEDIUM' 'HARD' 'SOFT' 'INTERMEDIATE' 'WET']\n",
      "\n",
      "\n",
      "LapStartTime : 2320 ['0 days 01:17:44.992000' '0 days 01:45:24.295000'\n",
      " '0 days 01:56:35.985000' ... '0 days 01:14:40.166000'\n",
      " '0 days 02:36:45.067000' '0 days 01:45:14.905000']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in f1_classif.select_dtypes(include=object).columns:\n",
    "    print(col, f\": {len(f1_classif[col].unique())}\", f1_classif[col].unique())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_classif['Compound'] = f1_classif['Compound'].map({'INTERMEDIATE':1, 'MEDIUM':4, 'HARD':2, 'SOFT':3, 'WET':0})\n",
    "\n",
    "f1_reg['Compound'] = f1_reg['Compound'].map({'INTERMEDIATE':1, 'MEDIUM':4, 'HARD':2, 'SOFT':3, 'WET':0})\n",
    "f1_reg['Pos_cat'] = f1_reg['Pos_cat'].map({'Participant':0, 'Podium':2, 'Point':1})\n",
    "\n",
    "train['Compound'] = train['Compound'].map({'INTERMEDIATE':1, 'MEDIUM':4, 'HARD':2, 'SOFT':3, 'WET':0})\n",
    "train['Pos_cat'] = train['Pos_cat'].map({'Participant':0, 'Podium':2, 'Point':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_days_remover (duration):\n",
    "    return duration.replace('0 days ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_att = []\n",
    "for col in f1_classif.select_dtypes(include=object).columns:\n",
    "    time_att.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Time',\n",
       " 'LapTime',\n",
       " 'Sector1Time',\n",
       " 'Sector2Time',\n",
       " 'Sector3Time',\n",
       " 'Sector1SessionTime',\n",
       " 'Sector2SessionTime',\n",
       " 'Sector3SessionTime',\n",
       " 'LapStartTime']"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in time_att:\n",
    "    f1_classif[time] = f1_classif[time].apply(zero_days_remover)\n",
    "    f1_reg[time] = f1_reg[time].apply(zero_days_remover)\n",
    "    train[time] = train[time].apply(zero_days_remover)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk memudahkan encoding waktu, kami menghilangkan 0 days karena seluruh data memiliki 0 days dan hal tersebut tidak membantu kami dalam melakukan encoding waktu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_converter (time_str):\n",
    "    if '.' in time_str:\n",
    "        time_str, milliseconds = time_str.split('.')\n",
    "        milliseconds = int(milliseconds)\n",
    "    else:\n",
    "        milliseconds = 0\n",
    "\n",
    "    x_time = datetime.datetime.strptime(time_str, '%H:%M:%S')\n",
    "\n",
    "    total_seconds = datetime.timedelta(\n",
    "        hours=x_time.hour,\n",
    "        minutes=x_time.minute,\n",
    "        seconds=x_time.second,\n",
    "        microseconds=milliseconds / 1000  # Convert milliseconds to microseconds\n",
    "    ).total_seconds()\n",
    "    \n",
    "    return total_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in time_att:\n",
    "    f1_classif[time] = f1_classif[time].apply(time_converter)\n",
    "    f1_reg[time] = f1_reg[time].apply(time_converter)\n",
    "    train[time] = train[time].apply(time_converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_columns = ['IsPersonalBest', 'FreshTyre', 'Deleted', 'Rainfall']\n",
    "f1_classif = pd.get_dummies(f1_classif, columns = boolean_columns, drop_first=True) \n",
    "f1_reg = pd.get_dummies(f1_reg, columns = boolean_columns, drop_first=True) \n",
    "train = pd.get_dummies(train, columns = boolean_columns, drop_first=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **KLASIFIKASI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Dataset Klasifikasi\n",
    "X_class_train = train.drop(columns=['Pos_cat'], axis=1)\n",
    "y_class_train = train['Pos_cat']\n",
    "\n",
    "X_class_test = f1_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_class_train)\n",
    "\n",
    "X_class_train = scaler.transform(X_class_train)\n",
    "X_class_test = scaler.transform(X_class_test)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "X_class_train = poly.fit_transform(X_class_train)\n",
    "X_class_test = poly.transform(X_class_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Hyperparameter\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {'criterion': ['entropy', 'gini'],\n",
    "               'min_samples_split': [5, 10, 15, 20, 25],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'max_depth' : [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "               'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], \n",
    "               }\n",
    "\n",
    "rf_f1_hp = RandomForestClassifier()\n",
    "clf_rfc_f1 = RandomizedSearchCV(rf_f1_hp, param_distributions=param_grid, cv=3, n_iter=100, n_jobs=-1, verbose=2, random_state=42)\n",
    "clf_rfc_f1.fit(X_class_train, y_class_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_f1_hp_applied = RandomForestClassifier(**clf_rfc_f1.best_params_)\n",
    "rf_f1_hp_applied.fit(X_class_train, y_class_train)\n",
    "# Memprediksi data testing\n",
    "predicted = rf_f1_hp_applied.predict(X_class_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif_df = pd.DataFrame({\n",
    "    'ID' : id_classif,\n",
    "    'Pos_cat' : predicted\n",
    "})\n",
    "\n",
    "classif_df['Pos_cat'] = classif_df['Pos_cat'].map({0: 'Participant', 2: 'Podium', 1: 'Point'})\n",
    "\n",
    "classif_df.to_csv('f1_classif_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **REGRESI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dan seleksi fitur Dataset Klasifikasi\n",
    "X_regress_train = train.drop(columns=['TyreLife'], axis=1)\n",
    "y_regress_train = train['TyreLife']\n",
    "X_regress_test = f1_reg\n",
    "\n",
    "#Standarisasi\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_regress_train = scaler.fit_transform(X_regress_train)\n",
    "X_regress_test = scaler.transform(X_regress_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=0.01)\n",
    "f1ridge = ridge.fit(X_regress_train, y_regress_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = f1ridge.predict(X_regress_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regress_df = pd.DataFrame({\n",
    "    'ID' : id_reg,\n",
    "    'TyreLife' : predicted\n",
    "})\n",
    "\n",
    "regress_df.to_csv('f1_reg_result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
