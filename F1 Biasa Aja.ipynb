{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **KASDD F1 Lap time - Biasa Aja**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library dan data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.stats as scp\n",
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "from decimal import Decimal\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "from sklearn.preprocessing import LabelEncoder, Normalizer, StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import chi2, mutual_info_regression, mutual_info_classif, SelectKBest, mutual_info_regression, SelectPercentile, mutual_info_regression, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, CategoricalNB\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold\n",
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import SilhouetteVisualizer, KElbowVisualizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "\n",
    "f1_data = pd.read_csv(\"f1_train.csv\")\n",
    "f1_data = f1_data.drop(axis=1, columns=[\"ID\"])\n",
    "f1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cek_duplicates(df):\n",
    "    if df.duplicated().sum() > 0:\n",
    "        print(\"Terdapat\", df.duplicated().sum(), \"pasang data yang redundan\")\n",
    "        display(df[df.duplicated()])\n",
    "    else:\n",
    "        print(\"Tidak ada data yang redundan\")\n",
    "\n",
    "def cek_null(df):\n",
    "    col_na = df.isnull().sum().sort_values(ascending=True)\n",
    "    percent = col_na*100 / len(df)\n",
    "\n",
    "    missing_data = pd.concat([col_na, percent], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "    if (missing_data[missing_data['Total'] > 0].shape[0] == 0):\n",
    "        print(\"Tidak ditemukan missing value pada dataset\")\n",
    "\n",
    "    else:\n",
    "        print(missing_data[missing_data['Total'] > 0])\n",
    "\n",
    "def cek_outlier(df):\n",
    "    df_numerical = df.select_dtypes(include=['float64', 'int64']) \n",
    "    Q1 = df_numerical.quantile(0.25, numeric_only=True)\n",
    "    Q3 = df_numerical.quantile(0.75, numeric_only=True)\n",
    "\n",
    "    # Menghitung RUB dan RLB.\n",
    "    IQR = Q3 - Q1\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Menampilkan banyaknya outlier pada atribut.\n",
    "    outliers = (df_numerical < lower_limit) | (df_numerical > upper_limit)\n",
    "\n",
    "    # Menghitung dan menampilkan persentase outlier pada tiap atribut.\n",
    "    percentage_outliers = (outliers.sum() / len(df)) * 100\n",
    "    print(\"Persentase Outlier pada tiap atribut:\")\n",
    "    print(percentage_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cek_null(f1_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Atribut `PitOutTime`, `PitInTime`, dan `DeletedReason` memiliki persentase jumlah missing value mencapai lebih dari 90%. Oleh karena itu, atribut-atribut tersebut perlu di drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_data = f1_data.drop(axis=1, columns=['PitOutTime', 'PitInTime', 'DeletedReason'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data_type_and_distribution(df):\n",
    "    print(\"Menampilkan informasi dataset dan tipe data\")\n",
    "    print('#'*50)\n",
    "    df.info()\n",
    "    print('#'*50)\n",
    "    print(\"Menampilkan distribusi data numerik\")\n",
    "    numerics = ['SpeedI2', 'SpeedFL', 'SpeedST', 'SpeedI1']\n",
    "    for col in numerics:\n",
    "        df_feature = f1_data[col]\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.title(f'Distribusi data {col}')\n",
    "        sns.kdeplot(df_feature, fill=True)\n",
    "        plt.show()\n",
    "    print(\"Menampilkan Modus dari data kategorikal\")\n",
    "    categoricals = [\"IsPersonalBest\", \"Sector2SessionTime\", \"Sector2Time\",\"Sector3SessionTime\", \"Sector3Time\", \"LapTime\", \"Sector1Time\", \"Sector1SessionTime\"]\n",
    "    for col in categoricals:\n",
    "        print(f\"Mode for {col} = {f1_data[col].mode()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data_type_and_distribution(f1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_null_mean(df):\n",
    "    mean = df.mean()\n",
    "    filled_df = df.fillna(mean)\n",
    "    return filled_df\n",
    "def fill_null_median(df):\n",
    "    median = df.median()\n",
    "    filled_df = df.fillna(median)\n",
    "    return filled_df\n",
    "def fill_null_mode(df):\n",
    "    mode = df.mode()[0]\n",
    "    filled_df = df.fillna(mode)\n",
    "    return filled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_data['SpeedI2'] = fill_null_median(f1_data['SpeedI2'])\n",
    "f1_data['SpeedFL'] = fill_null_median(f1_data['SpeedFL'])\n",
    "f1_data['SpeedST'] = fill_null_mean(f1_data['SpeedST'])\n",
    "f1_data['SpeedI1'] = fill_null_median(f1_data['SpeedI1'])\n",
    "f1_data['IsPersonalBest'] = fill_null_mode(f1_data['IsPersonalBest'])\n",
    "f1_data['Sector2SessionTime'] = fill_null_mode(f1_data['Sector2SessionTime'])\n",
    "f1_data['Sector2Time'] = fill_null_mode(f1_data['Sector2Time'])\n",
    "f1_data['Sector3SessionTime'] = fill_null_mode(f1_data['Sector3SessionTime'])\n",
    "f1_data['Sector3Time'] = fill_null_mode(f1_data['Sector3Time'])\n",
    "f1_data['LapTime'] = fill_null_mode(f1_data['LapTime'])\n",
    "f1_data['Sector1Time'] = fill_null_mode(f1_data['Sector1Time'])\n",
    "f1_data['Sector1SessionTime'] = fill_null_mode(f1_data['Sector1SessionTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cek_null(f1_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Duplicate Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Jumlah duplikasi data : \" + str(f1_data.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_data = f1_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_data.boxplot(vert=False,figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptime_numerical = f1_data.select_dtypes(include=['float64', 'int64']) \n",
    "Q1 = laptime_numerical.quantile(0.25)\n",
    "Q3 = laptime_numerical.quantile(0.75)\n",
    "IQR = Q3 - Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cek_outlier(f1_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Atribut `Presure` digunakan untuk memprediksi `TyreLife`, sehingga tidak kami drop ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Menampilkan nilai unique yang terdapat pada setiap kolom kategorikal\")\n",
    "print('#'*70)\n",
    "print()\n",
    "for col in f1_data.select_dtypes(include=object).columns:\n",
    "    print(col, f\": {len(f1_data[col].unique())}\", f1_data[col].unique())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_data['Compound'] = f1_data['Compound'].map({'INTERMEDIATE':1, 'MEDIUM':4, 'HARD':2, 'SOFT':3, 'WET':0})\n",
    "f1_data['Pos_cat'] = f1_data['Pos_cat'].map({'Participant':0, 'Podium':2, 'Point':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_days_remover (duration):\n",
    "    return duration.replace('0 days ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_att = []\n",
    "for col in f1_data.select_dtypes(include=object).columns:\n",
    "    time_att.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in time_att:\n",
    "    f1_data[time] = f1_data[time].apply(zero_days_remover)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk memudahkan encoding waktu, kami menghilangkan 0 days karena seluruh data memiliki 0 days dan hal tersebut tidak membantu kami dalam melakukan encoding waktu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_converter (time_str):\n",
    "    if '.' in time_str:\n",
    "        time_str, milliseconds = time_str.split('.')\n",
    "        milliseconds = int(milliseconds)\n",
    "    else:\n",
    "        milliseconds = 0\n",
    "\n",
    "    x_time = datetime.datetime.strptime(time_str, '%H:%M:%S')\n",
    "\n",
    "    total_seconds = datetime.timedelta(\n",
    "        hours=x_time.hour,\n",
    "        minutes=x_time.minute,\n",
    "        seconds=x_time.second,\n",
    "        microseconds=milliseconds / 1000  # Convert milliseconds to microseconds\n",
    "    ).total_seconds()\n",
    "    \n",
    "    return total_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in time_att:\n",
    "    f1_data[time] = f1_data[time].apply(time_converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time_period(seconds):\n",
    "    if 0 <= seconds < 6 * 3600:\n",
    "        return 3   # From 00:00 to 05:59\n",
    "    elif 6 * 3600 <= seconds < 12 * 3600:\n",
    "        return 0  # From 06:00 to 11:59\n",
    "    elif 12 * 3600 <= seconds < 17 * 3600:\n",
    "        return 1  # From 12:00 to 16:59\n",
    "    elif 17 * 3600 <= seconds < 21 * 3600:\n",
    "        return 2  # From 17:00 to 20:59\n",
    "    else:\n",
    "        return 3  # From 21:00 to 23:59\n",
    "f1_data['Time'] = f1_data['Time'].apply(convert_time_period)\n",
    "f1_data['LapStartTime'] = f1_data['LapStartTime'].apply(convert_time_period)\n",
    "\n",
    "f1_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EKSPLORASI** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apakah penggunaan ‘Compound’ yang berbeda berpengaruh terhadap performa? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performa dari suatu mobil F1 dapat ditentukan melalui waktu yang ditempuh mobil tersebut selama satu lap, yaitu atribut LapTime. Atribut ini juga kami pilih sebagai representasi performa yang dianalisis pengaruhnya oleh Compound karena dalam balapan F1, tipe compound yang berbeda tidak mungkin dipakai dalam satu lap yang sama. Oleh karena itu pada eksplorasi ini kami hanya mengambil atribut Compound dan LapTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compount_influence = f1_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compount_influence = compount_influence[['Compound', 'LapTime']]\n",
    "compount_influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compount_influence['Compound'] = compount_influence['Compound'].map({1: 'INTERMEDIATE', 4: 'MEDIUM', 2: 'HARD', 3: 'SOFT', 0: 'WET'})\n",
    "compount_influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compounds = compount_influence['Compound'].unique()\n",
    "for compound in compounds:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    subset = compount_influence[compount_influence['Compound'] == compound]['LapTime']\n",
    "    sns.kdeplot(subset, fill=True)\n",
    "    plt.title(f'KDE of Lap Times for {compound} Compound')\n",
    "    plt.xlabel('Lap Time')\n",
    "    plt.ylabel('Density')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_laptimes = compount_influence.groupby('Compound')['LapTime'].median()\n",
    "median_laptimes = median_laptimes.sort_values()\n",
    "median_laptimes.plot(kind='bar', figsize=(10, 6), color='skyblue')\n",
    "plt.title('Median Lap Times by Compound')\n",
    "plt.xlabel('Compound Type')\n",
    "plt.ylabel('Median Lap Time')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Grafik diatas adalah grafik yang menampilkan median LapTime dari setiap Compound dan diurutkan dari LapTime paling cepat hingga LapTime paling lambat\n",
    "\n",
    "> Berdasarkan visualisasi diatas, dapat dianalisis bahwa setiap tipe Compound dapat mempengaruhi performa mobil F1 karena menghasilkan LapTime yang berbeda-beda. Performa terbaik didapatkan ketika mobil-mobil F1 menggunakan Compound bertipe SOFT. Lalu, diikuti dengan tipe Compound HARD, MEDIUM, & INTERMEDIATE untuk performa terbaik kedua, ketiga, dan keempat. Untuk performa terburuk, didapatkan ketika mobil F1 menggunakan tipe Compound WET."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagaimana ciri-ciri driver dengan kategori posisi ‘Pos_cat’ Podium dibandingkan dengan kategori posisi lainnya?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis perbedaan ketika sirkuit hujan ‘Rainfall’ atau tidak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rain = f1_data.copy()\n",
    "#plt.figure(figsize=(40,40))\n",
    "#sns.heatmap(df_rain.corr(),annot=True)\n",
    "#plt.show()\n",
    "mean_attributes = ['LapTime', 'TyreLife', 'AirTemp', 'Humidity', 'TrackTemp','WindSpeed']\n",
    "mode_attributes = ['Compound']\n",
    "\n",
    "reverse_compound_mapping = {1: 'INTERMEDIATE', 4: 'MEDIUM', 2: 'HARD', 3: 'SOFT', 0: 'WET'}\n",
    "df_rain['Compound'] = df_rain['Compound'].map(reverse_compound_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LapTime         100.00078\n",
       "TyreLife              7.0\n",
       "AirTemp              17.5\n",
       "Humidity             66.0\n",
       "TrackTemp            27.3\n",
       "WindSpeed             1.7\n",
       "Compound     INTERMEDIATE\n",
       "dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rainfall_data = df_rain[df_rain['Rainfall'] == True]\n",
    "rainfall_mean = rainfall_data[mean_attributes].median()\n",
    "rainfall_mode = rainfall_data[mode_attributes].mode().iloc[0]\n",
    "\n",
    "rainfall_combined = pd.concat([rainfall_mean, rainfall_mode])\n",
    "rainfall_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LapTime      88.0006\n",
       "TyreLife        12.0\n",
       "AirTemp         25.6\n",
       "Humidity        54.0\n",
       "TrackTemp       34.3\n",
       "WindSpeed        1.5\n",
       "Compound        HARD\n",
       "dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_rainfall_data = df_rain[df_rain['Rainfall'] == False]\n",
    "no_rainfall_mean = no_rainfall_data[mean_attributes].median()\n",
    "no_rainfall_mode = no_rainfall_data[mode_attributes].mode().iloc[0]\n",
    "\n",
    "no_rainfall_combined = pd.concat([no_rainfall_mean, no_rainfall_mode])\n",
    "no_rainfall_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di sini, kami akan melakukan perbandingan kondisi balapan ketika sirkuit 'Rainfall' dan tidak dengan asumsi bahwa data ini adalah kumpulan dari balapan-balapan satu musim di lokasi dan waktu yg berbeda. Dari data yang telah diolah, kami menemukan bahwa terdapat beberapa aspek yang berbeda dari sirkuit 'Rainfall' dan tidak.  LapTime dari dua keadaan sirkuit ini berbeda cukup signifikan, di mana dalam keadaan 'Rainfall' diperlukan lebih banyak waktu untuk melakukan 'LapTime' jika dibandingkan dengan track tidak 'Rainfall'. Dari segi 'AirTemp', sirkuit 'Rainfall' memiliki temperatur udara yang lebih rendah. Selain itu, sirkuit 'Rainfall' memiliki temperatur track yang lebih rendah, serta memiliki 'humidity' lebih tinggi jika dibanding track yang tidak 'Rainfall'. Ban Intermediate menjadi ban yang sering dipakai pada sirkuit 'Rainfall'. Di sirkuit yang tidak 'Rainfall', temperatur track lebih tinggi dibanding track 'Rainfall' dan memiliki 'WindDirection' lebih tinggi dibanding track 'Rainfall'. Adapun 'Compound' ban yang sering dipakai untuk sirkuit tidak 'Rainfall' adalah ban berjenis Hard. Kedua tipe sirkuit ini tidak berbeda terlalu jauh jika kita tinjau dari segi 'Pressure' atau tekanan udara."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adakah rentang umur ban ‘TyreLife’ dengan performa terbaik dibandingkan rentang umur ban lainnya?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LapTime', 'Stint', 'Sector2SessionTime', 'Sector3SessionTime',\n",
       "       'Compound', 'TyreLife'], dtype=object)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **REGRESI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/analytics-vidhya/evaluation-metrics-for-regression-models-c91c65d73af\n",
    "def regression_metrics(prediction, y_test):\n",
    "    MAE = mean_absolute_error(y_test, prediction)\n",
    "    MSE = mean_squared_error(y_test, prediction)\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    R_squared = r2_score(y_test, prediction)\n",
    "\n",
    "    print('MAE: ' + str(MAE))\n",
    "    print('MSE: ' + str(MSE))\n",
    "    print('RMSE: ' + str(RMSE))\n",
    "    print('R_squared: ' + str(R_squared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Time', 'Sector1SessionTime', 'Sector2SessionTime',\n",
       "       'Sector3SessionTime', 'IsPersonalBest', 'LapStartTime'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split dan seleksi fitur Dataset Klasifikasi\n",
    "X_regression_temp = f1_data.drop(columns=['TyreLife'], axis=1)\n",
    "y_regression = f1_data['TyreLife']\n",
    "\n",
    "mi = mutual_info_classif(X_regression_temp, y_regression)\n",
    "mi = pd.Series(mi)\n",
    "mi.index = X_regression_temp.columns\n",
    "mi.sort_values(ascending=False)\n",
    "\n",
    "KBest = math.ceil(0.2 * len(mi.index))\n",
    "\n",
    "selector = SelectKBest(f_classif, k=KBest) \n",
    "X_regression = selector.fit_transform(X_regression_temp, y_regression)\n",
    "input_features = selector.feature_names_in_\n",
    "selector.get_feature_names_out(input_features=input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_regress_train, X_regress_test, y_regress_train, y_regress_test = train_test_split(X_regression, y_regression, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standarisasi\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_regress_train = scaler.fit_transform(X_regress_train)\n",
    "X_regress_test = scaler.transform(X_regress_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 6.137120378113992\n",
      "MSE: 77.34947622957323\n",
      "RMSE: 8.794855099975964\n",
      "R_squared: 0.2608282015802822\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_f1 = RandomForestRegressor()\n",
    "rf_f1.fit(X_regress_train, y_regress_train)\n",
    "\n",
    "# Memprediksi data testing\n",
    "predicted = rf_f1.predict(X_regress_test)\n",
    "regression_metrics(predicted, y_regress_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_f1 = [0.01, 0.1, 1, 10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model_f1 = []\n",
    "for alpha in alpha_f1:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_regress_train, y_regress_train)\n",
    "    ridge_model_f1.append(ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Ridge regression ke 1\n",
      "MSE: 81.7962100988712\n",
      "MAE: 6.888393576178069\n",
      "RMSE: 9.044125723300798\n",
      "R-squared: 0.21833405124489613\n",
      "\n",
      "Model Ridge regression ke 2\n",
      "MSE: 81.78529252020888\n",
      "MAE: 6.888197893738592\n",
      "RMSE: 9.043522130243774\n",
      "R-squared: 0.21843838247824887\n",
      "\n",
      "Model Ridge regression ke 3\n",
      "MSE: 81.94989425782168\n",
      "MAE: 6.89039537093234\n",
      "RMSE: 9.052618088587504\n",
      "R-squared: 0.21686540527988818\n",
      "\n",
      "Model Ridge regression ke 4\n",
      "MSE: 82.33758539221103\n",
      "MAE: 6.910074858994292\n",
      "RMSE: 9.074006027781282\n",
      "R-squared: 0.213160527535307\n",
      "\n",
      "Model Ridge regression ke 5\n",
      "MSE: 82.47068319951873\n",
      "MAE: 6.920911352696065\n",
      "RMSE: 9.081337082143726\n",
      "R-squared: 0.21188861012372218\n",
      "\n",
      "Model terbaik adalah model ke-2 dengan alpha=0.1\n",
      "Metrik Evaluasi - MSE: 81.78529252020888, MAE: 6.888197893738592, RMSE: 9.043522130243774, R-squared: 0.21843838247824887\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics_list = []\n",
    "counter = 1\n",
    "for model in ridge_model_f1:\n",
    "    y_pred = model.predict(X_regress_test)\n",
    "    mse = metrics.mean_squared_error(y_regress_test, y_pred)\n",
    "    mae = metrics.mean_absolute_error(y_regress_test, y_pred)\n",
    "    rmse = math.sqrt(mse)\n",
    "    r2 = metrics.r2_score(y_regress_test, y_pred)\n",
    "    \n",
    "    metrics_list.append((alpha_f1[counter-1], mse, mae, rmse, r2))\n",
    "    \n",
    "    print(f'Model Ridge regression ke {counter}')\n",
    "    print(\"MSE:\", mse)\n",
    "    print(\"MAE:\", mae)\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"R-squared:\", r2)\n",
    "    print()\n",
    "    counter += 1\n",
    "\n",
    "# Find the best model based on RMSE (you can change the criteria if needed)\n",
    "best_model_idx = min(range(len(metrics_list)), key=lambda i: metrics_list[i][3])  # Using RMSE for selection\n",
    "best_model = ridge_model_f1[best_model_idx]\n",
    "\n",
    "print(f'Model terbaik adalah model ke-{best_model_idx + 1} dengan alpha={metrics_list[best_model_idx][0]}')\n",
    "print(f'Metrik Evaluasi - MSE: {metrics_list[best_model_idx][1]}, MAE: {metrics_list[best_model_idx][2]}, RMSE: {metrics_list[best_model_idx][3]}, R-squared: {metrics_list[best_model_idx][4]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=0.01)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=0.01)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_ridge = ridge_model_f1[0]\n",
    "selected_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **KLASIFIKASI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasifikasi digunakan untuk membuat model dengan target `Pos_cat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LapTime', 'Stint', 'Sector2SessionTime', 'Sector3SessionTime',\n",
       "       'Compound', 'TyreLife'], dtype=object)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split Dataset Klasifikasi\n",
    "X_classification_temp = f1_data.drop(columns=['Pos_cat'], axis=1)\n",
    "y_classification = f1_data['Pos_cat']\n",
    "\n",
    "mi = mutual_info_classif(X_classification_temp, y_classification)\n",
    "mi = pd.Series(mi)\n",
    "mi.index = X_classification_temp.columns\n",
    "mi.sort_values(ascending=False)\n",
    "\n",
    "KBest = math.ceil(0.2 * len(mi.index))\n",
    "\n",
    "selector = SelectKBest(f_classif, k=KBest) \n",
    "X_classification = selector.fit_transform(X_classification_temp, y_classification)\n",
    "input_features = selector.feature_names_in_\n",
    "selector.get_feature_names_out(input_features=input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_class_train, X_class_test, y_class_train, y_class_test = train_test_split(X_classification, y_classification, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standarisasi\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_class_train)\n",
    "X_test_scaled = scaler.transform(X_class_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree  \n",
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "\n",
    "def classification_metrics(prediction, y_test):\n",
    "    print(f'Accuracy: {accuracy_score(y_test, prediction)}')\n",
    "    print('F1 Macro Average:', f1_score(y_test, prediction, average='macro'))\n",
    "    print('F1 Micro Average:', f1_score(y_test, prediction, average='micro'))\n",
    "    print('Precision Macro Average:', precision_score(y_test, prediction, average='macro',zero_division=0))\n",
    "    print('Precision Micro Average:', precision_score(y_test, prediction, average='micro',zero_division=0))\n",
    "    print('Recall Macro Average:', recall_score(y_test, prediction, average='macro',zero_division=0))\n",
    "    print('Recall Micro Average:', recall_score(y_test, prediction, average='micro',zero_division=0))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7046301224055349\n",
      "F1 Macro Average: 0.6649015164752367\n",
      "F1 Micro Average: 0.7046301224055349\n",
      "Precision Macro Average: 0.6790462028000986\n",
      "Precision Micro Average: 0.7046301224055349\n",
      "Recall Macro Average: 0.6558950652387289\n",
      "Recall Micro Average: 0.7046301224055349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_f1 = RandomForestClassifier()\n",
    "rf_f1.fit(X_train_scaled, y_class_train)\n",
    "\n",
    "# Memprediksi data testing\n",
    "predicted = rf_f1.predict(X_test_scaled)\n",
    "classification_metrics(predicted, y_class_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Hyperparameter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
